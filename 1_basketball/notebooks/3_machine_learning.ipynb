{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "\n",
    "### Binary Classificaition\n",
    "- Predict whether someone will beat their previous season's free throw score\n",
    "\n",
    "#### Input \n",
    "- Previous season scores? \n",
    "- Player name? \n",
    "\n",
    "#### Features\n",
    "- team - players can change right but just assume that it's constant per season\n",
    "- num_scoring_games\n",
    "- mean score per game\n",
    "- (consecutive) years they've exceeded previous record?\n",
    "- max score per game\n",
    "- actual scores per game per season ~ 100 => too high dim\n",
    "- number of years player has exceeded their previous scores \n",
    "- whether they beat last year\n",
    "- whether their team made it to playoffs last season - will be implied by game count\n",
    "\n",
    "#### Limitations\n",
    "- getting players per team is a bit time consuming\n",
    "- check which team score increased after any free throw is scored\n",
    "\n",
    "#### Models\n",
    "- Log Reg\n",
    "- Dec Trees\n",
    "- MLP\n",
    "\n",
    "#### Accuracy Metrics\n",
    "- Precision\n",
    "- Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "\n",
    "from src.feature_generation import get_season_features, get_previous_score_info, add_target_info, encode_categorical_field\n",
    "from src.utilities import add_info_a, add_info_b\n",
    "from src.mlp import train_mlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/formatted_free_throws.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get basic features from season data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = get_season_features(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Sequential data about previous year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = get_previous_score_info(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Target data from next year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = add_target_info(features_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encode team field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_features_df, encoded_teams = encode_categorical_field(full_df, 'team')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_features_df = encoded_features_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = [\n",
    "    'total_score',\n",
    "    'mean_score',\n",
    "    'max_score',\n",
    "    'num_games',\n",
    "    'previous_delta',\n",
    "    'beat_previous_score'\n",
    "]\n",
    "FEATURES.extend(encoded_teams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total features: 39\n"
     ]
    }
   ],
   "source": [
    "print(\"Total features: {}\".format(len(FEATURES)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Annotated Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate data points with missing targets i.e. target == -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total annotations: 3428\n"
     ]
    }
   ],
   "source": [
    "labelled_df = encoded_features_df.loc[encoded_features_df.target != -1]\n",
    "\n",
    "print(\"Total annotations: {}\".format(len(labelled_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled_df.to_csv('../../data/feature_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total +ve samples: 1506 [43.93%]\n",
      "Total -ve samples: 1922 [56.07%]\n"
     ]
    }
   ],
   "source": [
    "pos = len(labelled_df.loc[labelled_df.target == 1])\n",
    "neg = len(labelled_df.loc[labelled_df.target == 0])\n",
    "total = len(labelled_df)\n",
    "\n",
    "print(\"Total +ve samples: {} [{:.2f}%]\".format(pos, (pos/total * 100.0)))\n",
    "print(\"Total -ve samples: {} [{:.2f}%]\".format(neg, (neg/total * 100.0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train X Shape: (2742, 39)\n",
      "Train Y Shape: (2742,)\n",
      "Test X Shape: (686, 39)\n",
      "Test Y Shape: (686,)\n"
     ]
    }
   ],
   "source": [
    "labelled_df = labelled_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "target = np.ravel(labelled_df[['target']])\n",
    "\n",
    "full_train_x, full_test_x, train_y, test_y = train_test_split(labelled_df, target, test_size=0.2)\n",
    "\n",
    "\n",
    "train_x = full_train_x[FEATURES]\n",
    "test_x = full_test_x[FEATURES]\n",
    "\n",
    "print(\"Train X Shape: {}\".format(train_x.shape))\n",
    "print(\"Train Y Shape: {}\".format(train_y.shape))\n",
    "print(\"Test X Shape: {}\".format(test_x.shape))\n",
    "print(\"Test Y Shape: {}\".format(test_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "## Train Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Coeffs Shape: (1, 39)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sdaly/.virtualenvs/curve/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(class_weight='balanced')\n",
    "model.fit(train_x, train_y)\n",
    "\n",
    "print('Model Coeffs Shape: {}'.format(model.coef_.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision 0.557632398753894\n",
      "Recall 0.5966666666666667\n",
      "F Score 0.5764895330112721\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.63      0.65       386\n",
      "           1       0.56      0.60      0.58       300\n",
      "\n",
      "   micro avg       0.62      0.62      0.62       686\n",
      "   macro avg       0.61      0.61      0.61       686\n",
      "weighted avg       0.62      0.62      0.62       686\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true = np.array(test_y)\n",
    "y_pred = np.array(model.predict(test_x))\n",
    "\n",
    "print(\"Precision %s\" % metrics.precision_score(y_true, y_pred))\n",
    "print(\"Recall %s\" % metrics.recall_score(y_true, y_pred))\n",
    "print(\"F Score %s\" % metrics.f1_score(y_true, y_pred))\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Decision Trees Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight='balanced', criterion='gini',\n",
       "            max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(class_weight='balanced')\n",
    "model.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision 0.4738675958188153\n",
      "Recall 0.4533333333333333\n",
      "F Score 0.46337308347529815\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.61      0.60       386\n",
      "           1       0.47      0.45      0.46       300\n",
      "\n",
      "   micro avg       0.54      0.54      0.54       686\n",
      "   macro avg       0.53      0.53      0.53       686\n",
      "weighted avg       0.54      0.54      0.54       686\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true = np.array(test_y)\n",
    "y_pred = np.array(model.predict(test_x))\n",
    "\n",
    "print(\"Precision %s\" % metrics.precision_score(y_true, y_pred))\n",
    "print(\"Recall %s\" % metrics.recall_score(y_true, y_pred))\n",
    "print(\"F Score %s\" % metrics.f1_score(y_true, y_pred))\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train MLP Model\n",
    "\n",
    "- very basic POC implementation to validate whether approach is worthwhile\n",
    "- used keras for speed\n",
    "- **no** model optimisation/regularisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_37 (Dense)             (None, 256)               10240     \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 109,057\n",
      "Trainable params: 109,057\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2467 samples, validate on 275 samples\n",
      "Epoch 1/20\n",
      "2467/2467 [==============================] - 1s 485us/step - loss: 0.6953 - acc: 0.5878 - val_loss: 0.6434 - val_acc: 0.6545\n",
      "Epoch 2/20\n",
      "2467/2467 [==============================] - 0s 126us/step - loss: 0.6671 - acc: 0.6101 - val_loss: 0.6557 - val_acc: 0.6400\n",
      "Epoch 3/20\n",
      "2467/2467 [==============================] - 0s 144us/step - loss: 0.6664 - acc: 0.6105 - val_loss: 0.6324 - val_acc: 0.6691\n",
      "Epoch 4/20\n",
      "2467/2467 [==============================] - 0s 114us/step - loss: 0.6610 - acc: 0.6068 - val_loss: 0.6328 - val_acc: 0.6436\n",
      "Epoch 5/20\n",
      "2467/2467 [==============================] - 0s 120us/step - loss: 0.6579 - acc: 0.6096 - val_loss: 0.6212 - val_acc: 0.6545\n",
      "Epoch 6/20\n",
      "2467/2467 [==============================] - 0s 129us/step - loss: 0.6553 - acc: 0.6121 - val_loss: 0.6274 - val_acc: 0.6509\n",
      "Epoch 7/20\n",
      "2467/2467 [==============================] - 0s 111us/step - loss: 0.6554 - acc: 0.6072 - val_loss: 0.6256 - val_acc: 0.6436\n",
      "Epoch 8/20\n",
      "2467/2467 [==============================] - 0s 123us/step - loss: 0.6513 - acc: 0.6165 - val_loss: 0.6199 - val_acc: 0.6545\n",
      "Epoch 9/20\n",
      "2467/2467 [==============================] - 0s 128us/step - loss: 0.6474 - acc: 0.6149 - val_loss: 0.6270 - val_acc: 0.6655\n",
      "Epoch 10/20\n",
      "2467/2467 [==============================] - 0s 128us/step - loss: 0.6506 - acc: 0.6194 - val_loss: 0.6178 - val_acc: 0.6545\n",
      "Epoch 11/20\n",
      "2467/2467 [==============================] - 0s 131us/step - loss: 0.6472 - acc: 0.6202 - val_loss: 0.6284 - val_acc: 0.6655\n",
      "Epoch 12/20\n",
      "2467/2467 [==============================] - 0s 131us/step - loss: 0.6483 - acc: 0.6202 - val_loss: 0.6182 - val_acc: 0.6655\n",
      "Epoch 13/20\n",
      "2467/2467 [==============================] - 0s 126us/step - loss: 0.6528 - acc: 0.6173 - val_loss: 0.6162 - val_acc: 0.6545\n",
      "Epoch 14/20\n",
      "2467/2467 [==============================] - 0s 133us/step - loss: 0.6469 - acc: 0.6178 - val_loss: 0.6293 - val_acc: 0.6545\n",
      "Epoch 15/20\n",
      "2467/2467 [==============================] - 0s 106us/step - loss: 0.6438 - acc: 0.6198 - val_loss: 0.6153 - val_acc: 0.6545\n",
      "Epoch 16/20\n",
      "2467/2467 [==============================] - 0s 118us/step - loss: 0.6408 - acc: 0.6214 - val_loss: 0.6159 - val_acc: 0.6582\n",
      "Epoch 17/20\n",
      "2467/2467 [==============================] - 0s 135us/step - loss: 0.6381 - acc: 0.6178 - val_loss: 0.6135 - val_acc: 0.6582\n",
      "Epoch 18/20\n",
      "2467/2467 [==============================] - 0s 118us/step - loss: 0.6430 - acc: 0.6226 - val_loss: 0.6215 - val_acc: 0.6655\n",
      "Epoch 19/20\n",
      "2467/2467 [==============================] - 0s 142us/step - loss: 0.6383 - acc: 0.6230 - val_loss: 0.6156 - val_acc: 0.6655\n",
      "Epoch 20/20\n",
      "2467/2467 [==============================] - 0s 130us/step - loss: 0.6358 - acc: 0.6230 - val_loss: 0.6224 - val_acc: 0.6400\n"
     ]
    }
   ],
   "source": [
    "mlp = train_mlp(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision 0.7142857142857143\n",
      "Recall 0.15\n",
      "F Score 0.24793388429752064\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.95      0.73       386\n",
      "           1       0.71      0.15      0.25       300\n",
      "\n",
      "   micro avg       0.60      0.60      0.60       686\n",
      "   macro avg       0.65      0.55      0.49       686\n",
      "weighted avg       0.64      0.60      0.52       686\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true = np.array(test_y)\n",
    "y_pred = np.array([int(round(pred)) for pred in mlp.predict(test_x).flatten()])\n",
    "\n",
    "print(\"Precision %s\" % metrics.precision_score(y_true, y_pred))\n",
    "print(\"Recall %s\" % metrics.recall_score(y_true, y_pred))\n",
    "print(\"F Score %s\" % metrics.f1_score(y_true, y_pred))\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "- Majority of time spent on data and feature generation\n",
    "- 3 models test very quickly to see if solutions are valid or whether more feature engineering required\n",
    "- While no model is highly performant\n",
    "    - the log reg model scores the highest f score (~0.56) \n",
    "    - the neurel network based approach scores both the highest precision (~0.71) and the lowest recall (~0.15)\n",
    "    \n",
    "- From a product perspective, predicting whether a player will exceed their previous year's total scores seems like a precision focused tasked, therefore I would prioritise another iteration on both data features and model advancements, in particular experimenting with the MLP approach as it shows the most potential; as the first model arch demonstarated the significantly higher precision than the other ml models it seems plausible tuning and better/more features will increase performance\n",
    "- Next steps:\n",
    "    - visualise false positives/negatives to understand why model is going wrong\n",
    "    - increase/update features based on above findings\n",
    "    - implement mlp in tensorflow for more custom and less 'out of box' model, add reg and tune etc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
